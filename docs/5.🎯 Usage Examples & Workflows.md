# ğŸ¯ Usage Examples & Workflows

## ğŸš€ Quick Start Examples

### Basic Book Processing

#### Process a Single PDF Book
```bash
# Activate virtual environment
source .venv/bin/activate

# Process PDF with verbose output
python book_processor.py "books/cracking-the-pm-career.pdf" --output "book_chapters" --verbose

# Expected Output:
# ğŸš€ Processing .PDF: books/cracking-the-pm-career.pdf
# ğŸ“‹ STEP 1: Finding Table of Contents...
# ğŸ” STEP 2: Scanning for chapter pages...
# ğŸ”— STEP 3: Merging TOC with found pages...
# ğŸ“Š STEP 4: Calculating page ranges...
# ğŸ‘€ STEP 5: Preview...
# ğŸš€ Proceed with chapter extraction? [Y/n]: y
# ğŸ“ STEP 6: Creating directories...
# ğŸ”„ STEP 7: Extracting 37 chapters...
# âœ… Book processing completed successfully!
```

#### Process a Single EPUB Book
```bash
# Process EPUB with image extraction and PDF conversion
python book_processor.py "books/decode-and-conquer.epub" --output "book_chapters" --verbose

# Expected Output:
# ğŸš€ Processing .EPUB: books/decode-and-conquer.epub
# ğŸ“‹ STEP 1: Extracting EPUB chapters directly...
# ğŸ‘€ STEP 2: Preview...
# ğŸ“ STEP 3: Creating directories...
# ğŸ”„ STEP 4: Extracting 24 chapters with smart numbering...
# ğŸ–¼ï¸ Extracting images for chapter 1...
# ğŸ”§ Converting HTML to PDF: Chapter_01-Critiquing_Design.html
# âœ… Created: Chapter_01-Critiquing_Design.pdf
# âœ… Book processing completed successfully!
```

---

## ğŸ¤– AI Summarization Workflows

### Single Chapter Summarization

#### Generate ChatGPT Summary
```bash
# Navigate to AI summarizer directory
cd AI_summarizer

# Summarize a single chapter with ChatGPT
python chatgpt_summarizer.py "../book_chapters/cracking-the-pm-career_chapters/C._Product_Skills/Chapter_14-Getting_Analytical_Metrics.pdf"

# Expected Output:
# âœ… Environment variables loaded from .env file
# âœ… OpenAI library imported successfully
# ğŸ”‘ OpenAI API client initialized successfully
# 
# ğŸš€ Processing: Chapter_14-Getting_Analytical_Metrics
# ============================================================
# ğŸ“„ Extracting text from: Chapter_14-Getting_Analytical_Metrics.pdf
# âœ… Successfully extracted 8,234 characters using pdfplumber
# âœ… Content size OK: ~2,058 tokens
# ğŸ¤– Sending to ChatGPT for summarization...
# âœ… Received summary: 3,456 characters
# ğŸ’¾ Saved summary: Chapter_14-Getting_Analytical_Metrics_chatgpt_summary.md
# 
# ğŸ‰ Chapter summarization complete!
```

#### Generate Claude Summary
```bash
# Summarize the same chapter with Claude
python claude_summarizer.py "../book_chapters/cracking-the-pm-career_chapters/C._Product_Skills/Chapter_14-Getting_Analytical_Metrics.pdf"

# Expected Output:
# âœ… Environment variables loaded from .env file
# âœ… Anthropic library imported successfully
# ğŸ”‘ Claude API client initialized successfully
# 
# ğŸš€ Processing: Chapter_14-Getting_Analytical_Metrics
# ============================================================
# ğŸ“„ Extracting text from: Chapter_14-Getting_Analytical_Metrics.pdf
# âœ… Successfully extracted 8,234 characters using pdfplumber
# âœ… Content size OK: ~1,372 tokens
# ğŸ¤– Sending to Claude for summarization...
# âœ… Received summary: 4,123 characters
# ğŸ’¾ Saved summary: Chapter_14-Getting_Analytical_Metrics_claude_summary.md
# 
# ğŸ‰ Chapter summarization complete!
```

### Batch Summarization

#### Summarize All Chapters in a Book
```bash
# Summarize all chapters in a book folder with ChatGPT
python chatgpt_summarizer.py "../book_chapters/cracking-the-pm-career_chapters" --batch --recursive

# Expected Output:
# ğŸ“ Searching recursively in: ../book_chapters/cracking-the-pm-career_chapters
# ğŸ“„ Found 37 PDF files to process
# 
# ğŸ“„ Processing Chapter_01-Introduction.pdf...
#    ğŸ“‚ Location: ../book_chapters/cracking-the-pm-career_chapters/A._Foreword
# ğŸš€ Processing: Chapter_01-Introduction
# âœ… Received summary: 2,834 characters
# ğŸ’¾ Saved summary: Chapter_01-Introduction_chatgpt_summary.md
# 
# ğŸ“„ Processing Chapter_02-Getting_Interviews.pdf...
# [... continues for all chapters ...]
# 
# ğŸ‰ Complete! Successfully processed 37/37 chapters
```

#### Parallel Processing with Both AI Services
```bash
# Process with ChatGPT in background
nohup python chatgpt_summarizer.py "../book_chapters/decode-and-conquer_chapters" --batch -r > chatgpt.log 2>&1 &

# Process with Claude simultaneously  
nohup python claude_summarizer.py "../book_chapters/decode-and-conquer_chapters" --batch -r > claude.log 2>&1 &

# Monitor progress
tail -f chatgpt.log
tail -f claude.log
```

---

## ğŸ“ File Organization Workflows

### Typical Output Structure

#### PDF Book Output (Sectioned)
```
book_chapters/cracking-the-pm-career_chapters/
â”œâ”€â”€ A._Foreword/
â”‚   â”œâ”€â”€ Chapter_01-Introduction.pdf
â”‚   â”œâ”€â”€ Chapter_01-Introduction_chatgpt_summary.md
â”‚   â”œâ”€â”€ Chapter_01-Introduction_claude_summary.md
â”‚   â””â”€â”€ Chapter_02-Getting_Interviews.pdf
â”œâ”€â”€ B._Storytelling/  
â”‚   â”œâ”€â”€ Chapter_03-Storytelling_Framework.pdf
â”‚   â””â”€â”€ Chapter_04-Leadership_Stories.pdf
â”œâ”€â”€ C._Product_Skills/
â”‚   â”œâ”€â”€ Chapter_05-Product_Sense.pdf
â”‚   â”œâ”€â”€ Chapter_06-Analytical_Thinking.pdf
â”‚   â””â”€â”€ [...more chapters...]
â”œâ”€â”€ D._Technical_Skills/
â”‚   â””â”€â”€ [...technical chapters...]
â”œâ”€â”€ E._Behavioral_Skills/
â”‚   â””â”€â”€ [...behavioral chapters...]
â””â”€â”€ cracking-the-pm-career_processing_report.json
```

#### EPUB Book Output (Flat Structure)
```
book_chapters/decode-and-conquer_chapters/
â”œâ”€â”€ Chapters/
â”‚   â”œâ”€â”€ Chapter_01-Critiquing_Design.pdf           # Real chapters
â”‚   â”œâ”€â”€ Chapter_01-Critiquing_Design_chatgpt_summary.md
â”‚   â”œâ”€â”€ Chapter_01-Critiquing_Design_claude_summary.md
â”‚   â”œâ”€â”€ Chapter_02-Designing_a_Desktop_Application.pdf
â”‚   â”œâ”€â”€ Chapter_03-Designing_a_Webpage_or_Website.pdf
â”‚   â”œâ”€â”€ [...more real chapters...]
â”‚   â”œâ”€â”€ Extra_01-Introduction.pdf                  # Supporting content
â”‚   â”œâ”€â”€ Extra_02-Practice.pdf
â”‚   â””â”€â”€ Extra_03-Acknowledgments.pdf
â””â”€â”€ decode-and-conquer_processing_report.json
```

---

## ğŸ”§ Advanced Usage Patterns

### Custom Output Organization
```bash
# Process to specific directory structure
python book_processor.py "books/pm-interview.pdf" --output "study_materials/pm_prep" --verbose

# Result:
# study_materials/pm_prep/pm-interview_chapters/
```

### Processing Multiple Books
```bash
# Process multiple books sequentially
for book in books/*.pdf; do
    echo "Processing: $book"
    python book_processor.py "$book" --output "book_chapters" --verbose
    sleep 5  # Brief pause between books
done
```

### Selective Chapter Processing
```bash
# Process only specific chapters (manual selection)
python book_processor.py "books/large-book.pdf" --output "test_chapters" --verbose
# When prompted, type 'n' to cancel, then manually extract specific chapters
```

---

## ğŸ” Quality Control & Validation

### Verify Processing Results
```bash
# Check extraction completeness
find book_chapters/ -name "*.pdf" | wc -l
# Should match number of chapters in processing report

# Validate JSON reports
python -c "
import json
with open('book_chapters/book-name_chapters/book-name_processing_report.json') as f:
    report = json.load(f)
    print(f'Processed: {report[\"book_info\"][\"total_chapters\"]} chapters')
    print(f'Files created: {report[\"book_info\"][\"total_files\"]}')
"
```

### Check AI Summary Quality
```bash
# Count summary files
find book_chapters/ -name "*_summary.md" | wc -l

# Check summary sizes (should be substantial)
find book_chapters/ -name "*_summary.md" -exec wc -c {} + | sort -n

# Sample summary content
head -50 book_chapters/*/Chapters/*_chatgpt_summary.md
```

---

## ğŸš¨ Error Recovery Workflows

### Resume Failed Processing
```bash
# If processing failed, check what was completed
ls -la book_chapters/book-name_chapters/

# Remove incomplete output and retry
rm -rf book_chapters/book-name_chapters/
python book_processor.py "books/book-name.pdf" --output "book_chapters" --verbose
```

### Handle Partial AI Processing
```bash
# Find chapters without summaries
cd book_chapters/book-name_chapters/
for pdf in */*.pdf; do
    base="${pdf%.pdf}"
    if [[ ! -f "${base}_chatgpt_summary.md" ]]; then
        echo "Missing ChatGPT summary: $pdf"
    fi
    if [[ ! -f "${base}_claude_summary.md" ]]; then
        echo "Missing Claude summary: $pdf"
    fi
done

# Process missing summaries
cd ../../AI_summarizer
python chatgpt_summarizer.py "../book_chapters/book-name_chapters/path/to/missing-chapter.pdf"
```

---

## ğŸ“Š Monitoring & Analytics

### Processing Statistics
```bash
# Count books processed
find book_chapters/ -name "*_processing_report.json" | wc -l

# Total chapters extracted
find book_chapters/ -name "Chapter_*.pdf" | wc -l

# Total summaries generated
find book_chapters/ -name "*_summary.md" | wc -l

# Disk usage
du -sh book_chapters/
```

### Performance Tracking
```bash
# Time a complete workflow
time {
    python book_processor.py "books/test-book.pdf" --output "test_output" --verbose
    cd AI_summarizer
    python chatgpt_summarizer.py "../test_output/test-book_chapters" --batch
    python claude_summarizer.py "../test_output/test-book_chapters" --batch
}
```

---

## ğŸ¯ Production Workflows

### Daily Processing Routine
```bash
#!/bin/bash
# daily_processing.sh

# Activate environment
source .venv/bin/activate

# Process new books
for book in books/new/*.{pdf,epub}; do
    if [[ -f "$book" ]]; then
        echo "Processing: $book"
        python book_processor.py "$book" --output "book_chapters" --verbose
        
        # Move processed book
        mv "$book" books/processed/
    fi
done

# Generate summaries for new chapters
cd AI_summarizer
find ../book_chapters/ -name "Chapter_*.pdf" -newer ../last_run.timestamp -exec echo "Summarizing: {}" \; -exec python chatgpt_summarizer.py "{}" \;

# Update timestamp
touch ../last_run.timestamp
```

### Backup & Archive
```bash
# Create backup of processed books
tar -czf "backup_$(date +%Y%m%d).tar.gz" book_chapters/

# Archive old summaries
find book_chapters/ -name "*_summary.md" -mtime +30 -exec mv {} archive/ \;

# Clean up old processing reports
find book_chapters/ -name "*_processing_report.json" -mtime +90 -delete
```

### Integration with Notion
```bash
# Convert summaries to Notion-compatible format
for summary in book_chapters/*/Chapters/*_chatgpt_summary.md; do
    # Summaries are already Notion-ready, just copy to Notion import folder
    cp "$summary" notion_import/
done
```

This comprehensive usage guide covers all major workflows from basic processing to advanced production scenarios.