# ðŸ“ Book Summarizer - Complete File Structure & Function Mapping

## Project Overview
**Book Summarizer** is a comprehensive system for processing books (PDF/EPUB) into individual chapters and generating AI-powered study summaries. Built for Python 3.12+ with modular architecture.

```
BookProcessor/                              # ðŸ“ Project Root
â”œâ”€â”€ .env                                    # ðŸ”’ API keys (create from .env.example)
â”œâ”€â”€ .env.example                            # ðŸ“ API key template
â”œâ”€â”€ .gitignore                              # ðŸš« Git exclusions
â”œâ”€â”€ requirements.txt                        # ðŸ“¦ Python dependencies
â”œâ”€â”€ book_processor.py                       # ðŸš€ Main CLI entry point
â”œâ”€â”€ test_regression.py                      # ðŸ§ª Regression testing for processed books
â”œâ”€â”€ README.md                               # ðŸ“– Project documentation
â”‚
â”œâ”€â”€ AI_summarizer/                          # ðŸ¤– AI Summarization Tools
â”‚   â”œâ”€â”€ chatgpt_summarizer.py              # ðŸ’¬ OpenAI ChatGPT integration
â”‚   â”œâ”€â”€ claude_summarizer.py               # ðŸ§  Anthropic Claude integration
â”‚   â”œâ”€â”€ pdf_text_extractor.py              # ðŸ“„ PDF text extraction utilities
â”‚   â””â”€â”€ prompt_template.py                 # ðŸ“ Shared AI prompt templates
â”‚
â”œâ”€â”€ book_processing/                        # âš™ï¸ Core Processing Engine
â”‚   â”œâ”€â”€ main.py                            # ðŸŽ¯ Processing orchestrator (45 lines)
â”‚   â”œâ”€â”€ pdf_processor.py                   # ðŸ“„ Complete PDF workflow processor
â”‚   â”œâ”€â”€ epub_processor.py                  # ðŸ“š Complete EPUB workflow processor (with image extraction)
â”‚   â”œâ”€â”€ toc_parser.py                      # ðŸ“‹ Table of Contents parsing
â”‚   â”œâ”€â”€ chapter_detector.py                # ðŸ” Chapter detection algorithms
â”‚   â”œâ”€â”€ epub_image_extractor.py            # ðŸ–¼ï¸ EPUB image extraction & processing
â”‚   â”œâ”€â”€ html_to_pdf_converter.py           # ðŸ”„ HTMLâ†’PDF conversion (Playwright/WeasyPrint)
â”‚   â”œâ”€â”€ report_generator.py                # ðŸ“Š Processing reports & summaries
â”‚   â””â”€â”€ utils.py                           # ðŸ› ï¸ Shared utility functions
â”‚
â”œâ”€â”€ books/                                  # ðŸ“š Source Materials
â”‚   â”œâ”€â”€ *.pdf                              # ðŸ“„ Source PDF books
â”‚   â””â”€â”€ *.epub                             # ðŸ“– Source EPUB books
â”‚
â”œâ”€â”€ book_chapters/                          # ðŸ“ Processed Output
â”‚   â”œâ”€â”€ book-name_chapters/                # ðŸ“‚ Individual book folders
â”‚   â”‚   â”œâ”€â”€ A._Section_Name/               # ðŸ“ Section-based organization (PDFs)
â”‚   â”‚   â”‚   â”œâ”€â”€ Chapter_01-Title.pdf      # ðŸ“„ Individual chapter PDFs
â”‚   â”‚   â”‚   â””â”€â”€ Chapter_02-Title.pdf
â”‚   â”‚   â”œâ”€â”€ Chapters/                      # ðŸ“ Flat organization (EPUBs)  
â”‚   â”‚   â”‚   â”œâ”€â”€ Chapter_01-Title.pdf      # ðŸ“„ EPUB chapters as PDFs (with images)
â”‚   â”‚   â”‚   â”œâ”€â”€ Chapter_02-Title.pdf
â”‚   â”‚   â”‚   â”œâ”€â”€ Extra_01-Introduction.pdf # ðŸ“„ Supporting content
â”‚   â”‚   â”‚   â””â”€â”€ *_chatgpt_summary.md      # ðŸ¤– AI-generated summaries
â”‚   â”‚   â”‚   â””â”€â”€ *_claude_summary.md       # ðŸ§  AI-generated summaries
â”‚   â”‚   â””â”€â”€ book-name_processing_report.json # ðŸ“Š Processing metadata
â”‚   â””â”€â”€ [additional books...]
â”‚
â””â”€â”€ test_chapters_clean_section/           # ðŸ§ª Test Output Directory
    â””â”€â”€ [same structure as book_chapters/]
```

---

## ðŸ“„ File Function Mapping

### ðŸš€ **book_processor.py** (Main CLI Entry Point)
```python
def main()                          # CLI argument parsing & execution
def process_single_book()           # Process one book file  
def process_batch()                 # Process multiple books
def setup_logging()                 # Configure verbose output
```
**Purpose**: Command-line interface for book processing. Routes to appropriate processors based on file type.

---

### ðŸŽ¯ **book_processing/main.py** (Ultra-Minimal Orchestrator - 45 lines)
```python
class BookProcessor:
    def __init__(verbose)           # Initialize all processors
    def process_book()              # Route PDF/EPUB to appropriate processor
    def _process_pdf_book()         # Delegate to PDFProcessor.process_pdf_book()
    def _process_epub_book()        # Delegate to EPUBProcessor.process_epub_book()
```
**Purpose**: Pure orchestrator that routes requests to specialized processors. No implementation details.

---

### ðŸ“„ **book_processing/pdf_processor.py** (Complete PDF Workflow - 200 lines)
```python
class PDFProcessor:
    def __init__(verbose)                        # Initialize dependencies (TOCParser, ChapterDetector, ReportGenerator)
    def process_pdf_book(pdf_path, output_dir)   # Complete PDF workflow (8 steps)
    def create_chapter_pdfs()                    # Extract individual PDF chapters
    def _get_pdf_page_count()                    # Count total pages using PyMuPDF
    def _create_pdf_section_directories()        # Create section-based folder structure
    def _get_user_confirmation()                 # Interactive confirmation prompt
```
**Purpose**: Handles complete PDF processing workflow from TOC parsing to chapter extraction.

**8-Step PDF Workflow**:
1. Parse Table of Contents â†’ Uses TOCParser
2. Scan for actual chapter pages â†’ Uses ChapterDetector  
3. Merge TOC with detected pages â†’ Uses ChapterDetector
4. Calculate page ranges â†’ Uses ChapterDetector
5. Show preview & get confirmation â†’ Uses ReportGenerator
6. Create section directories â†’ Internal logic
7. Extract individual PDFs â†’ Uses PyPDF2
8. Generate reports â†’ Uses ReportGenerator

---

### ðŸ“š **book_processing/epub_processor.py** (Complete EPUB Workflow - 400 lines)
```python
class EPUBProcessor:
    def __init__(verbose)                        # Initialize image extractor & PDF converter
    def process_epub_book(epub_path, output_dir) # Complete EPUB workflow (4 steps)
    def _extract_epub_chapters_direct()          # Extract chapters from EPUB structure
    def _extract_epub_title()                    # Extract chapter titles from HTML
    def _show_epub_preview()                     # Display extraction preview
    def _create_epub_directories()               # Create output folder structure
    def _extract_epub_chapters_with_images()     # Process chapters with image extraction
    def _create_epub_chapter_html_with_images()  # Create HTML with embedded images
    def _clean_chapter_title()                   # Remove redundant chapter numbering
    def _get_user_confirmation()                 # Interactive confirmation prompt
    def _finalize_epub_processing()              # Generate reports and summaries
    def _save_processing_report()                # JSON report generation
    def _show_completion_summary()               # Display final results
```
**Purpose**: Handles complete EPUB processing from extraction to PDF conversion with image preservation.

**4-Step EPUB Workflow**:
1. Extract EPUB structure â†’ Direct document parsing
2. Show preview with smart numbering â†’ Chapter vs Extra classification  
3. Create directories â†’ Flat "Chapters" structure
4. Extract chapters â†’ HTML creation â†’ Image extraction â†’ PDF conversion

---

### ðŸ“‹ **book_processing/toc_parser.py** (Table of Contents Parsing)
```python
class TOCParser:
    def find_toc_pages()                    # Locate TOC pages in PDF
    def extract_chapters_from_toc()         # Parse chapter information from TOC
    def _parse_toc_text()                   # Extract structured data from TOC text
    def _detect_toc_format()                # Identify TOC format (sectioned vs flat)
    def _parse_sectioned_toc()              # Handle books with sections (A. B. C.)
    def _parse_flat_toc()                   # Handle books with simple chapter lists
```
**Purpose**: Parses Table of Contents from PDFs to extract chapter information and page numbers.

---

### ðŸ” **book_processing/chapter_detector.py** (Chapter Detection Algorithms)
```python
class ChapterDetector:
    def scan_for_chapters()                 # Scan PDF for actual chapter start pages
    def merge_toc_with_pages()              # Combine TOC data with detected pages
    def calculate_page_ranges()             # Determine start/end pages for each chapter
    def _detect_chapter_patterns()          # Find "CHAPTER X" patterns in text
    def _validate_chapter_pages()           # Verify detected pages are valid
    def _handle_missing_pages()             # Handle chapters without detected pages
```
**Purpose**: Detects actual chapter start pages in PDFs and merges with TOC information.

---

### ðŸ–¼ï¸ **book_processing/epub_image_extractor.py** (EPUB Image Processing)
```python
class EPUBImageExtractor:
    def extract_chapter_images()            # Extract images from EPUB ZIP for specific chapter
    def _find_image_references()            # Locate image tags in HTML content
    def _extract_from_zip()                 # Extract image files from EPUB ZIP
    def _update_html_paths()                # Update HTML img src paths to local files
```
**Purpose**: Extracts images from EPUB files and updates HTML content to reference local image files.

---

### ðŸ”„ **book_processing/html_to_pdf_converter.py** (HTMLâ†’PDF Conversion)
```python
class HTMLToPDFConverter:
    def convert_html_to_pdf()               # Convert HTML to PDF and cleanup
    def _convert_with_playwright()          # Primary conversion using Playwright/Chromium
    def _convert_with_weasyprint()          # Fallback conversion using WeasyPrint
    def _cleanup_html()                     # Delete HTML file after conversion
    def _cleanup_image_folder()             # Delete chapter image folders after conversion
    def set_backend()                       # Choose preferred conversion backend
```
**Purpose**: Converts HTML chapter files to PDF format with multiple backend support and cleanup.

---

### ðŸ“Š **book_processing/report_generator.py** (Processing Reports)
```python
class ReportGenerator:
    def generate_processing_report()        # Create comprehensive JSON report
    def create_extraction_preview()         # Visual preview of extraction plan
    def print_processing_summary()          # Display final processing results
    def organize_output_structure()         # Create organized directory structure
```
**Purpose**: Generates processing reports, previews, and summaries for both PDF and EPUB workflows.

---

### ðŸ› ï¸ **book_processing/utils.py** (Shared Utilities)
```python
def sanitize_filename()                     # Clean filenames for cross-platform compatibility
def estimate_file_size()                    # Estimate PDF file size based on page count
def get_book_metadata()                     # Extract basic book information
def create_directory_structure()            # Create nested directory structures
def validate_file_format()                 # Verify file format and accessibility
```
**Purpose**: Shared utility functions used across multiple processors.

---

## ðŸ¤– AI Summarization Tools

### ðŸ’¬ **AI_summarizer/chatgpt_summarizer.py** (OpenAI Integration)
```python
class ChatGPTSummarizer:
    def __init__(api_key)                   # Initialize OpenAI client with .env support
    def summarize_chapter()                 # Send chapter to ChatGPT for summarization
    def save_summary()                      # Save summary as Notion-ready markdown
    def process_single_chapter()            # Process one PDF chapter
    def process_folder()                    # Batch process multiple chapters
def main()                                  # CLI interface with argparse
```
**Purpose**: Processes extracted PDF chapters through OpenAI ChatGPT API for study guide generation.

---

### ðŸ§  **AI_summarizer/claude_summarizer.py** (Anthropic Integration)
```python
class ClaudeSummarizer:
    def __init__(api_key)                   # Initialize Claude client with .env support
    def summarize_chapter()                 # Send chapter to Claude for summarization
    def save_summary()                      # Save summary as Notion-ready markdown
    def process_single_chapter()            # Process one PDF chapter
    def process_folder()                    # Batch process multiple chapters
def main()                                  # CLI interface with argparse
```
**Purpose**: Processes extracted PDF chapters through Anthropic Claude API for study guide generation.

---

### ðŸ“„ **AI_summarizer/pdf_text_extractor.py** (PDF Text Extraction)
```python
def extract_text_from_pdf()                # Extract text using pdfplumber + PyPDF2 fallback
def check_content_length()                 # Validate content fits within LLM context limits
def get_pdf_info()                         # Get PDF metadata (pages, size, etc.)
```
**Purpose**: Shared PDF text extraction utilities for AI summarizers with dual extraction methods.

---

### ðŸ“ **AI_summarizer/prompt_template.py** (AI Prompts)
```python
def get_summarization_prompt()             # Generate comprehensive summarization prompt
```
**Purpose**: Single source of truth for AI summarization prompts used by both ChatGPT and Claude.

---

## ðŸ“¦ Configuration Files

### **requirements.txt** (Python Dependencies)
```
# Core PDF/EPUB Processing
PyPDF2>=3.0.1
pdfplumber>=0.7.6  
ebooklib>=0.18
beautifulsoup4>=4.12.2

# AI APIs
openai>=1.0.0
anthropic>=0.7.0

# Environment Management  
python-dotenv>=1.0.0

# HTMLâ†’PDF Conversion
playwright>=1.40.0

# Image Processing
Pillow>=10.0.0
```

### **.env.example** (API Key Template)
```
# Copy to .env and add your actual API keys
OPENAI_API_KEY=sk-your_openai_key_here
ANTHROPIC_API_KEY=sk-ant-your_anthropic_key_here
```

---

## ðŸŽ¯ Key Architectural Principles

1. **Separation of Concerns**: Each module handles one specific domain
2. **Delegation Pattern**: Main.py delegates to specialized processors  
3. **Modular Design**: Processors can be used independently
4. **Error Handling**: Graceful degradation with informative messages
5. **User Experience**: Interactive confirmations and detailed progress reporting
6. **Security**: API keys managed via .env files with .gitignore protection