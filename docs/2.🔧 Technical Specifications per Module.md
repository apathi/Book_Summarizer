# ğŸ”§ Technical Specifications per Module

## ğŸ“„ PDF Processing Specifications

### **Core PDF Processing Libraries**
- **PyPDF2**: PDF manipulation and page extraction
- **pdfplumber**: Advanced text extraction with layout preservation
- **PyMuPDF (fitz)**: Page counting and metadata extraction

### **PDF Processing Data Flow**
```
PDF Input â†’ TOC Parsing â†’ Chapter Detection â†’ Page Range Calculation â†’ Directory Creation â†’ PDF Extraction â†’ Report Generation
```

### **Supported PDF Formats**
1. **Sectioned Books**: Books with hierarchical structure (A. Section, B. Section)
   - Example: "A. Foreword", "C. Product Skills", "D. Technical Skills"
   - Creates nested folder structure: `A._Foreword/`, `C._Product_Skills/`

2. **Flat Structure Books**: Simple chapter lists  
   - Example: "Chapter 1", "Chapter 2", "Chapter 3"
   - Creates single folder: `Chapters/`

### **TOC Detection Patterns**
```python
# Sectioned Format Detection
r'^([A-Z])\.\s*(.+)$'              # A. Foreword
r'^([0-9]+)\.\s*(.+)$'             # 1. Introduction  

# Chapter Format Detection  
r'^CHAPTER\s+(\d+)\s+(.+?)\s*\.{2,}\s*(\d+)\s*$'  # CHAPTER 1 TITLE ... 10
r'^CHAPTER\s+(\d+)\s+(.+?)\s+(\d+)\s*$'           # CHAPTER 1 TITLE 10
```

### **Chapter Detection Algorithm**
1. **Text Pattern Matching**: Scan for "CHAPTER X" patterns in page text
2. **Position Validation**: Verify chapters appear at logical page positions
3. **TOC Cross-Reference**: Match detected pages with TOC entries
4. **Gap Analysis**: Handle missing or misaligned chapters

---

## ğŸ“š EPUB Processing Specifications

### **Core EPUB Processing Libraries**
- **ebooklib**: EPUB file structure parsing
- **BeautifulSoup4**: HTML content parsing and manipulation
- **zipfile**: Direct EPUB ZIP file access for image extraction

### **EPUB Processing Data Flow**
```
EPUB Input â†’ Direct Chapter Extraction â†’ Smart Classification â†’ Image Extraction â†’ HTML Creation â†’ PDF Conversion â†’ Cleanup
```

### **Chapter Classification Logic**
```python
# Real Chapter Detection (becomes Chapter_XX)
pattern = r'^(CHAPTER|Chapter)\s+\d+\s+\w'
# Must have: CHAPTER + number + space + descriptive text

# Supporting Content (becomes Extra_XX)  
# Examples: "Introduction", "Chapter 003", "Acknowledgments"
```

### **Image Extraction Process**
1. **ZIP Parsing**: Extract EPUB as ZIP file
2. **Image Discovery**: Find image references in HTML content
3. **File Extraction**: Extract image files to chapter-specific folders
4. **Path Updates**: Update HTML img src paths to local references
5. **Format Conversion**: Convert to web-compatible formats if needed

### **HTMLâ†’PDF Conversion Pipeline**
```
HTML with Images â†’ Playwright/Chromium Rendering â†’ PDF Generation â†’ File Cleanup
```

**Conversion Backends**:
- **Primary**: Playwright + Chromium (best compatibility)
- **Fallback**: WeasyPrint (lighter weight, fewer dependencies)

---

## ğŸ¤– AI Summarization Specifications

### **Supported AI Providers**
1. **OpenAI ChatGPT**
   - Model: `gpt-4o` (latest GPT-4)
   - Context Limit: ~120,000 tokens
   - Output Limit: 4,000 tokens
   - Temperature: 0.1 (consistent, factual output)

2. **Anthropic Claude**
   - Model: `claude-3-5-sonnet-20241022`
   - Context Limit: ~180,000 tokens
   - Output Limit: 8,000 tokens  
   - Temperature: 0.1 (consistent, factual output)

### **Text Extraction Methods**
```python
# Primary: pdfplumber (better for complex layouts)
with pdfplumber.open(pdf_path) as pdf:
    text = page.extract_text()

# Fallback: PyPDF2 (broader compatibility)  
with open(pdf_path, 'rb') as file:
    text = page.extract_text()
```

### **Content Length Validation**
```python
# Token estimation: ~4 characters per token
estimated_tokens = len(content) // 4
if estimated_tokens > max_tokens:
    # Content too large for context window
```

### **Prompt Engineering**
- **Single Source Template**: Shared prompt across both AI providers
- **Study-Focused**: Optimized for PM interview preparation
- **Notion-Ready**: Formatted for direct import to Notion
- **Comprehensive**: Covers frameworks, examples, memory aids

---

## ğŸ—‚ï¸ File Organization Specifications

### **PDF Output Structure (Sectioned Books)**
```
book-name_chapters/
â”œâ”€â”€ A._Foreword/
â”‚   â”œâ”€â”€ Chapter_01-Title.pdf
â”‚   â””â”€â”€ Chapter_02-Title.pdf
â”œâ”€â”€ C._Product_Skills/  
â”‚   â”œâ”€â”€ Chapter_03-Title.pdf
â”‚   â””â”€â”€ Chapter_04-Title.pdf
â””â”€â”€ book-name_processing_report.json
```

### **EPUB Output Structure (Flat Organization)**
```
book-name_chapters/
â”œâ”€â”€ Chapters/
â”‚   â”œâ”€â”€ Chapter_01-Real_Chapter_Title.pdf      # Actual chapters
â”‚   â”œâ”€â”€ Chapter_02-Another_Chapter.pdf
â”‚   â”œâ”€â”€ Extra_01-Introduction.pdf              # Supporting content
â”‚   â”œâ”€â”€ Extra_02-Acknowledgments.pdf
â”‚   â””â”€â”€ [summaries after AI processing]
â”‚       â”œâ”€â”€ Chapter_01-Real_Chapter_Title_chatgpt_summary.md
â”‚       â”œâ”€â”€ Chapter_01-Real_Chapter_Title_claude_summary.md
â”‚       â””â”€â”€ [additional summaries...]
â””â”€â”€ book-name_processing_report.json
```

### **Processing Report Format**
```json
{
  "book_info": {
    "book_name": "string",
    "file_type": "PDF|EPUB", 
    "total_chapters": "number",
    "total_files": "number",
    "processing_date": "ISO-8601"
  },
  "chapters": [
    {
      "id": "string",
      "title": "string", 
      "start_page": "number",
      "end_page": "number",
      "section": "string",
      "section_title": "string",
      "page_range": "string"
    }
  ],
  "extracted_files": ["array of file paths"]
}
```

---

## ğŸ”’ Security & Configuration

### **API Key Management**
- **Storage**: `.env` file (excluded from version control)
- **Loading**: `python-dotenv` library
- **Fallback**: System environment variables
- **Validation**: API key format validation on initialization

### **File Safety**
- **Input Validation**: File existence and format verification
- **Path Sanitization**: Cross-platform filename cleaning
- **Error Handling**: Graceful degradation with informative messages
- **Cleanup**: Automatic removal of temporary files

### **Memory Management**
- **Chunked Processing**: Large files processed in segments
- **Context Limits**: Content validation before API calls
- **Resource Cleanup**: Proper file handle management
- **Error Recovery**: Rollback mechanisms for failed operations

---

## ğŸ“Š Performance Characteristics

### **Processing Times (Estimated)**
- **PDF TOC Parsing**: 5-15 seconds
- **Chapter Detection**: 10-30 seconds (depends on page count)
- **PDF Extraction**: 1-2 seconds per chapter
- **EPUB Processing**: 20-60 seconds (depends on images)
- **AI Summarization**: 30-120 seconds per chapter

### **File Size Estimates**
- **PDF Chapters**: 200KB-5MB per chapter (depends on page count)
- **EPUB Chapters**: 500KB-10MB per chapter (includes images)
- **AI Summaries**: 5-15KB per markdown file

### **Scalability Considerations**
- **Batch Processing**: Processes multiple files sequentially
- **Memory Usage**: ~50-200MB per book (depends on size)
- **Disk Space**: 2-5x source file size for complete output
- **API Limits**: Respects provider rate limits and context windows

---

## ğŸ§ª Error Handling & Recovery

### **Common Error Scenarios**
1. **Missing Dependencies**: Clear installation instructions
2. **Invalid API Keys**: Helpful setup guidance  
3. **Corrupted Files**: Graceful skipping with error logs
4. **Insufficient Disk Space**: Pre-processing validation
5. **Network Issues**: Retry mechanisms for API calls

### **Recovery Mechanisms**
- **Partial Processing**: Continue with remaining chapters if some fail
- **Resume Capability**: Skip already processed chapters
- **Fallback Methods**: Multiple extraction approaches
- **User Feedback**: Clear progress indicators and error messages

### **Logging & Debugging**
- **Verbose Mode**: Detailed operation logging
- **Error Traces**: Full stacktraces in verbose mode
- **Progress Indicators**: Real-time processing updates
- **Validation Checks**: Pre-flight verification steps